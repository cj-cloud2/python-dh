## Lab 1: The Foundation (Pure Python Data Parsing)

In this first 30-minute lab, you will play the role of a Data Engineer who has just received a raw export from a legacy transit system. You cannot use high-level libraries yet. You must use "Vanilla" Python to open, read, and sanitize the data.

### Detailed Requirements for Lab 1

1. **File Ingestion:** Open the `transit_data.csv` file using the built-in `open()` function.
2. **Data Cleaning:** * Strip whitespace from headers and values.
* Normalize `transit_type` to Title Case (e.g., "bus" or "BUS" becomes "Bus").


3. **Missing Value Handling:** Replace empty strings in the `passenger_count` column with a default value of `0`.
4. **Data Structuring:** Store the cleaned data in a "List of Dictionaries" format for easy access.
5. **Initial Calculation:** Calculate the total ridership across all stations using a standard `for` loop.

---

### Step 1: Create the Source Data

Before we can process data, we need a file to work with. We will use Python's file writing capabilities to generate our "dirty" CSV.

**Step Description:**
Use a multi-line string and the `write` method to create a physical file on your disk/environment.

**Logic & Planning:**

```python
# Create a variable containing the raw CSV text data.
# Open a new file named 'transit_data.csv' in write mode.
# Write the text data into the file.
# Close the file connection to save changes.

```

**Solution:**

```python
# Assign a multi-line string to the raw_data variable
raw_data = """timestamp,station_id,transit_type,passenger_count,revenue,weather_temp
2025-01-01 08:00:00,STN_001,Bus,45,112.50,2.5
2025-01-01 08:15:00,STN_002,Metro,120,360.00,2.4
01/01/2025 08:30,STN_001,bus,38,,2.1
2025-01-01 09:00:00,STN_003,Metro,310,930.00,
2025-01-01 09:15:00,STN_002,Metro,,450.00,3.0
01-01-2025 09:30,STN_001,Bus,55,137.50,3.5"""

# Use the open function to create the file object in 'w' (write) mode
with open('transit_data.csv', 'w') as f:
    # Use the write method to save the string content to the file
    f.write(raw_data)

```

---

### Step 2: Read and Split the Data

To process the data, we must read the file and split the text into rows and columns.

**Step Description:**
Read the file content and split it by newline characters to get individual rows, then split by commas to get columns.

**Logic & Planning:**

```python
# Initialize an empty list to store our final data.
# Open the csv file in read mode.
# Read all lines from the file into a list.
# Extract the first line to use as headers and split it by commas.
# Loop through the remaining lines of the data.

```

**Solution:**

```python
# Create an empty list to hold our structured data
cleaned_data_list = []

# Open the file 'transit_data.csv' in 'r' (read) mode
with open('transit_data.csv', 'r') as f:
    # Read the file and split it into a list of strings by line breaks
    lines = f.read().splitlines()

# Use the split method on the first element to get a list of column names
headers = lines[0].split(',')

```

---

### Step 3: Clean and Normalize Data

Raw data is messy. We need to ensure the `transit_type` is consistent and handle missing passenger counts.

**Step Description:**
Iterate through each row, clean the strings, and handle the "Bus" vs "bus" inconsistency.

**Logic & Planning:**

```python
# Start a loop for every row in the lines list, skipping the header.
# Split the current row string into a list of values using a comma.
# Create a dictionary using the headers and current values.
# Clean the transit_type value by converting it to title case.
# Check if passenger_count is empty; if so, set it to '0'.

```

**Solution:**

```python
# Iterate through lines starting from the second element (index 1)
for line in lines[1:]:
    # Split the individual line string into a list of separate values
    values = line.split(',')
    
    # Use the dict and zip functions to pair headers with row values
    row_dict = dict(zip(headers, values))
    
    # Use the title method to make transit types consistent (e.g., 'Bus')
    row_dict['transit_type'] = row_dict['transit_type'].title()
    
    # Use an if statement to check if the passenger count string is empty
    if row_dict['passenger_count'] == '' or row_dict['passenger_count'] == 'NaN':
        # Assign '0' to the passenger_count key if no value exists
        row_dict['passenger_count'] = '0'
        
    # Append the completed dictionary to our master list
    cleaned_data_list.append(row_dict)

```

---

### Step 4: Perform Business Logic Calculation

Now that the data is structured, we can calculate the total ridership.

**Step Description:**
Loop through your list of dictionaries, convert the passenger count strings to integers, and sum them up.

**Logic & Planning:**

```python
# Initialize a counter variable at zero.
# Loop through every dictionary in your cleaned list.
# Convert the passenger_count value from a string to an integer.
# Add that integer to your total counter.
# Print the final total to the console.

```

**Solution:**

```python
# Set the initial total_riders variable to 0
total_riders = 0

# Loop through each dictionary entry in our cleaned_data_list
for record in cleaned_data_list:
    # Use the int function to transform the string number into an integer
    count = int(record['passenger_count'])
    # Use the addition assignment operator to add the count to the total
    total_riders += count

# Use the print function to display the final calculated result
print(f"Total Daily Ridership: {total_riders}")

```

---

### Final Instructions: Run the Application

To see your Data Engineering pipeline in action, copy all the **Solution** blocks into a single Python script or a single Jupyter Notebook cell.

1. The first block creates your "Database" (the CSV).
2. The second and third blocks act as your **ETL (Extract, Transform, Load)** process.
3. The final block provides your **Data Analysis**.
